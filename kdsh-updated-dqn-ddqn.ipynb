{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7377961,"sourceType":"datasetVersion","datasetId":4287447},{"sourceId":7423005,"sourceType":"datasetVersion","datasetId":4318970},{"sourceId":7429533,"sourceType":"datasetVersion","datasetId":4323434}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-01-19T20:12:04.837439Z","iopub.execute_input":"2024-01-19T20:12:04.838293Z","iopub.status.idle":"2024-01-19T20:12:05.278435Z","shell.execute_reply.started":"2024-01-19T20:12:04.838251Z","shell.execute_reply":"2024-01-19T20:12:05.277425Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/rl-dataset/priceData.xls\n/kaggle/input/rl-dataset/BTCUSDT.xlsx\n/kaggle/input/rl-dataset/Visualization.py\n/kaggle/input/rl-dataset/exports.xlsx\n/kaggle/input/rl-dataset/priceData.csv\n/kaggle/input/rl-dataset/priceData.xlsx\n/kaggle/input/rl-dataset/pandas_positioning.xlsx\n/kaggle/input/btc-usd-full-dataset/btc_3m.csv\n/kaggle/input/btc-usd-full-dataset/btc_1h.csv\n/kaggle/input/btc-usd-full-dataset/btc_15m.csv\n/kaggle/input/btc-usd-full-dataset/btc_30m.csv\n/kaggle/input/btc-usd-full-dataset/btc_4h.csv\n/kaggle/input/btc-usd-full-dataset/btc_6h.csv\n/kaggle/input/btc-usd-full-dataset/btc_2h.csv\n/kaggle/input/btc-usd-full-dataset/btc_5m.csv\n/kaggle/input/models/model_t-dqn_GOOG_10\n/kaggle/input/models/model_double-dqn_GOOG_50\n/kaggle/input/models/model_dqn_GOOG_50\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Method One : Using DQN and Double DQN","metadata":{}},{"cell_type":"code","source":"import random\n\nfrom collections import deque\n\nimport numpy as np\nimport tensorflow as tf\nimport keras.backend as K\n\nfrom keras.models import Sequential\nfrom keras.models import load_model, clone_model\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n\n\ndef huber_loss(y_true, y_pred, clip_delta=1.0):\n    \"\"\"Huber loss - Custom Loss Function for Q Learning\n\n    Links: \thttps://en.wikipedia.org/wiki/Huber_loss\n            https://jaromiru.com/2017/05/27/on-using-huber-loss-in-deep-q-learning/\n    \"\"\"\n    error = y_true - y_pred\n    cond = K.abs(error) <= clip_delta\n    squared_loss = 0.5 * K.square(error)\n    quadratic_loss = 0.5 * K.square(clip_delta) + clip_delta * (K.abs(error) - clip_delta)\n    return K.mean(tf.where(cond, squared_loss, quadratic_loss))\n\n\nclass Agent:\n    \"\"\" Stock Trading Bot \"\"\"\n\n    def __init__(self, state_size, strategy=\"t-dqn\", reset_every=1000, pretrained=False, model_name=None):\n        self.strategy = strategy\n\n        # agent config\n        self.state_size = state_size    \t# normalized previous days\n        self.action_size = 3           \t\t# [sit, buy, sell]\n        self.model_name = model_name\n        self.inventory = []\n        self.memory = deque(maxlen=10000)\n        self.first_iter = True\n\n        # model config\n        self.model_name = model_name\n        self.gamma = 0.95 # affinity for long term reward\n        self.epsilon = 1.0\n        self.epsilon_min = 0.01\n        self.epsilon_decay = 0.995\n        self.learning_rate = 0.001\n        self.loss = huber_loss\n        self.custom_objects = {\"huber_loss\": huber_loss}  # important for loading the model from memory\n        self.optimizer = Adam(lr=self.learning_rate)\n\n        if pretrained and self.model_name is not None:\n            self.model = self.load()\n        else:\n            self.model = self._model()\n\n        # strategy config\n        if self.strategy in [\"t-dqn\", \"double-dqn\"]:\n            self.n_iter = 1\n            self.reset_every = reset_every\n\n            # target network\n            self.target_model = clone_model(self.model)\n            self.target_model.set_weights(self.model.get_weights())\n\n    def _model(self):\n        \"\"\"Creates the model\n        \"\"\"\n        model = Sequential()\n        model.add(Dense(units=128, activation=\"relu\", input_dim=self.state_size))\n        model.add(Dense(units=256, activation=\"relu\"))\n        model.add(Dense(units=256, activation=\"relu\"))\n        model.add(Dense(units=128, activation=\"relu\"))\n        model.add(Dense(units=self.action_size))\n\n        model.compile(loss=self.loss, optimizer=self.optimizer)\n        return model\n\n    def remember(self, state, action, reward, next_state, done):\n        \"\"\"Adds relevant data to memory\n        \"\"\"\n        self.memory.append((state, action, reward, next_state, done))\n\n    def act(self, state, is_eval=False):\n        \"\"\"Take action from given possible set of actions\n        \"\"\"\n        # take random action in order to diversify experience at the beginning\n        if not is_eval and random.random() <= self.epsilon:\n            return random.randrange(self.action_size)\n\n        if self.first_iter:\n            self.first_iter = False\n            return 1 # make a definite buy on the first iter\n\n        action_probs = self.model.predict(state)\n        return np.argmax(action_probs[0])\n\n    def train_experience_replay(self, batch_size):\n        \"\"\"Train on previous experiences in memory\n        \"\"\"\n        mini_batch = random.sample(self.memory, batch_size)\n        X_train, y_train = [], []\n        \n        # DQN\n        if self.strategy == \"dqn\":\n            for state, action, reward, next_state, done in mini_batch:\n                if done:\n                    target = reward\n                else:\n                    # approximate deep q-learning equation\n                    target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n\n                # estimate q-values based on current state\n                q_values = self.model.predict(state)\n                # update the target for current action based on discounted reward\n                q_values[0][action] = target\n\n                X_train.append(state[0])\n                y_train.append(q_values[0])\n\n        # DQN with fixed targets\n        elif self.strategy == \"t-dqn\":\n            if self.n_iter % self.reset_every == 0:\n                # reset target model weights\n                self.target_model.set_weights(self.model.get_weights())\n\n            for state, action, reward, next_state, done in mini_batch:\n                if done:\n                    target = reward\n                else:\n                    # approximate deep q-learning equation with fixed targets\n                    target = reward + self.gamma * np.amax(self.target_model.predict(next_state)[0])\n\n                # estimate q-values based on current state\n                q_values = self.model.predict(state)\n                # update the target for current action based on discounted reward\n                q_values[0][action] = target\n\n                X_train.append(state[0])\n                y_train.append(q_values[0])\n\n        # Double DQN\n        elif self.strategy == \"double-dqn\":\n            if self.n_iter % self.reset_every == 0:\n                # reset target model weights\n                self.target_model.set_weights(self.model.get_weights())\n\n            for state, action, reward, next_state, done in mini_batch:\n                if done:\n                    target = reward\n                else:\n                    # approximate double deep q-learning equation\n                    target = reward + self.gamma * self.target_model.predict(next_state)[0][np.argmax(self.model.predict(next_state)[0])]\n\n                # estimate q-values based on current state\n                q_values = self.model.predict(state)\n                # update the target for current action based on discounted reward\n                q_values[0][action] = target\n\n                X_train.append(state[0])\n                y_train.append(q_values[0])\n                \n        else:\n            raise NotImplementedError()\n\n        # update q-function parameters based on huber loss gradient\n        loss = self.model.fit(\n            np.array(X_train), np.array(y_train),\n            epochs=1, verbose=0\n        ).history[\"loss\"][0]\n\n        # as the training goes on we want the agent to\n        # make less random and more optimal decisions\n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n\n        return loss\n\n    def save(self, episode):\n        self.model.save(\"models/{}_{}\".format(self.model_name, episode))\n\n    def load(self):\n        return load_model(\"models/\" + self.model_name, custom_objects=self.custom_objects)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T21:36:14.282381Z","iopub.execute_input":"2024-01-19T21:36:14.282780Z","iopub.status.idle":"2024-01-19T21:36:28.116770Z","shell.execute_reply.started":"2024-01-19T21:36:14.282749Z","shell.execute_reply":"2024-01-19T21:36:28.115688Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load the data\ndata_path = '/kaggle/input/btc-usd-full-dataset/btc_30m.csv'\nbtc_data = pd.read_csv(data_path)\n\n# Data preprocessing steps\n# Example: Normalize the 'close' prices\nscaler = MinMaxScaler()\nbtc_data['close'] = scaler.fit_transform(btc_data['close'].values.reshape(-1,1))\n\n# Display the first few rows of the processed data\nbtc_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:12:36.040656Z","iopub.execute_input":"2024-01-19T20:12:36.041623Z","iopub.status.idle":"2024-01-19T20:12:36.788320Z","shell.execute_reply.started":"2024-01-19T20:12:36.041588Z","shell.execute_reply":"2024-01-19T20:12:36.787218Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"              datetime      open      high       low     close      volume\n0  2018-01-01 05:30:00  13715.65  13715.65  13400.01  0.158158  221.752443\n1  2018-01-01 06:00:00  13500.00  13690.87  13450.00  0.158278  221.603756\n2  2018-01-01 06:30:00  13528.99  13595.89  13402.28  0.158752  160.399291\n3  2018-01-01 07:00:00  13559.99  13559.99  13155.38  0.153299  223.297715\n4  2018-01-01 07:30:00  13203.00  13411.76  13202.03  0.153634  203.728509","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-01 05:30:00</td>\n      <td>13715.65</td>\n      <td>13715.65</td>\n      <td>13400.01</td>\n      <td>0.158158</td>\n      <td>221.752443</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-01 06:00:00</td>\n      <td>13500.00</td>\n      <td>13690.87</td>\n      <td>13450.00</td>\n      <td>0.158278</td>\n      <td>221.603756</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-01 06:30:00</td>\n      <td>13528.99</td>\n      <td>13595.89</td>\n      <td>13402.28</td>\n      <td>0.158752</td>\n      <td>160.399291</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-01 07:00:00</td>\n      <td>13559.99</td>\n      <td>13559.99</td>\n      <td>13155.38</td>\n      <td>0.153299</td>\n      <td>223.297715</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-01 07:30:00</td>\n      <td>13203.00</td>\n      <td>13411.76</td>\n      <td>13202.03</td>\n      <td>0.153634</td>\n      <td>203.728509</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport random\nimport matplotlib.pyplot as plt\nfrom collections import deque\n\n# Simple Trading Environment\nclass TradingEnv:\n    def __init__(self, data, window_size=10):\n        self.data = data\n        self.window_size = window_size\n        self.reset()\n\n    def reset(self):\n        self.current_step = random.randint(self.window_size, len(self.data) - 1)\n        self.done = False\n        return self._get_state()\n\n    def _get_state(self):\n        return self.data['close'][self.current_step - self.window_size:self.current_step].values\n\n    def step(self, action):\n        # Assuming action is 0 (sell), 1 (hold), 2 (buy)\n        reward = 0\n        self.current_step += 1\n        if self.current_step >= len(self.data) - 1:\n            self.done = True\n        next_state = self._get_state()\n\n        # Simple reward function: price change times action (buy: +1, sell: -1)\n        if action == 2:\n            reward = self.data['close'][self.current_step] - self.data['close'][self.current_step - 1]\n        elif action == 0:\n            reward = self.data['close'][self.current_step - 1] - self.data['close'][self.current_step]\n\n        return next_state, reward, self.done, {}\n\n# Update the training loop\nenv = TradingEnv(btc_data, window_size=10)\nnum_episodes = 50\nrewards = []\n\nfor episode in range(num_episodes):\n    state = env.reset()\n    total_reward = 0\n    done = False\n    while not done:\n        action = random.choice([0, 1, 2])  # Random action for demonstration\n        next_state, reward, done, _ = env.step(action)\n        total_reward += reward\n    rewards.append(total_reward)\n    print(f\"Episode: {episode}, Total Reward: {total_reward}\")\n\n# Visualization of training results\nplt.plot(rewards)\nplt.title(\"Training Rewards over Episodes\")\nplt.xlabel(\"Episode\")\nplt.ylabel(\"Total Reward\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:12:56.127559Z","iopub.execute_input":"2024-01-19T20:12:56.127966Z","iopub.status.idle":"2024-01-19T20:15:10.098047Z","shell.execute_reply.started":"2024-01-19T20:12:56.127904Z","shell.execute_reply":"2024-01-19T20:15:10.096950Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Episode: 0, Total Reward: -0.14674715144908296\nEpisode: 1, Total Reward: 0.17167527512494318\nEpisode: 2, Total Reward: 0.416471019887687\nEpisode: 3, Total Reward: -0.04608119374422559\nEpisode: 4, Total Reward: -0.20786577953771795\nEpisode: 5, Total Reward: 0.36846625043418363\nEpisode: 6, Total Reward: -0.1501545367700446\nEpisode: 7, Total Reward: 0.056254469835168575\nEpisode: 8, Total Reward: 0.11826897432616007\nEpisode: 9, Total Reward: -0.760168769977751\nEpisode: 10, Total Reward: 0.5041847280339294\nEpisode: 11, Total Reward: -0.11180506951481683\nEpisode: 12, Total Reward: -0.3162758364491649\nEpisode: 13, Total Reward: 0.6790523170434004\nEpisode: 14, Total Reward: -0.33486469898705107\nEpisode: 15, Total Reward: -0.5214516955358339\nEpisode: 16, Total Reward: -0.33530752007664194\nEpisode: 17, Total Reward: -0.7974306600829504\nEpisode: 18, Total Reward: -0.2552690210675314\nEpisode: 19, Total Reward: 0.010873174756845128\nEpisode: 20, Total Reward: 0.10521438253570536\nEpisode: 21, Total Reward: -0.24296809580210715\nEpisode: 22, Total Reward: 0.40066097806790835\nEpisode: 23, Total Reward: -0.20480498305854467\nEpisode: 24, Total Reward: -0.4320322326095307\nEpisode: 25, Total Reward: -0.3522333977223878\nEpisode: 26, Total Reward: 0.27448492071227343\nEpisode: 27, Total Reward: 0.6751740047065236\nEpisode: 28, Total Reward: -0.7923164507347275\nEpisode: 29, Total Reward: 0.30947695176564183\nEpisode: 30, Total Reward: -0.06762285879430058\nEpisode: 31, Total Reward: -1.3939361769402607\nEpisode: 32, Total Reward: -0.27919006663244\nEpisode: 33, Total Reward: -0.04225710751525885\nEpisode: 34, Total Reward: -0.20689811082350923\nEpisode: 35, Total Reward: -0.8381680618306049\nEpisode: 36, Total Reward: 0.04550960474208127\nEpisode: 37, Total Reward: 0.2616654105557885\nEpisode: 38, Total Reward: 0.15379883672014405\nEpisode: 39, Total Reward: -0.87138697553042\nEpisode: 40, Total Reward: 0.19580589314065722\nEpisode: 41, Total Reward: -0.5867796443439429\nEpisode: 42, Total Reward: -0.37603209085791234\nEpisode: 43, Total Reward: -0.14303487792711173\nEpisode: 44, Total Reward: 0.40382686627168657\nEpisode: 45, Total Reward: 0.3609285159368284\nEpisode: 46, Total Reward: 0.05615289135136031\nEpisode: 47, Total Reward: 0.17783643022962958\nEpisode: 48, Total Reward: 0.15777872754084227\nEpisode: 49, Total Reward: 0.14901105326652547\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport math\nimport logging\n\nimport numpy as np\n\n\ndef sigmoid(x):\n    \"\"\"Performs sigmoid operation\n    \"\"\"\n    try:\n        if x < 0:\n            return 1 - 1 / (1 + math.exp(x))\n        return 1 / (1 + math.exp(-x))\n    except Exception as err:\n        print(\"Error in sigmoid: \" + err)\n\n\ndef get_state(data, t, n_days):\n    \"\"\"Returns an n-day state representation ending at time t\n    \"\"\"\n    d = t - n_days + 1\n    block = data[d: t + 1] if d >= 0 else -d * [data[0]] + data[0: t + 1]  # pad with t0\n    res = []\n    for i in range(n_days - 1):\n        res.append(sigmoid(block[i + 1] - block[i]))\n    return np.array([res])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:16:17.455404Z","iopub.execute_input":"2024-01-19T20:16:17.455804Z","iopub.status.idle":"2024-01-19T20:16:17.465105Z","shell.execute_reply.started":"2024-01-19T20:16:17.455775Z","shell.execute_reply":"2024-01-19T20:16:17.463942Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport math\nimport logging\n\nimport pandas as pd\nimport numpy as np\n\nimport keras.backend as K\n\n\n# Formats Position\nformat_position = lambda price: ('-$' if price < 0 else '+$') + '{0:.2f}'.format(abs(price))\n\n\n# Formats Currency\nformat_currency = lambda price: '${0:.2f}'.format(abs(price))\n\n\ndef show_train_result(result, val_position, initial_offset):\n    \"\"\" Displays training results\n    \"\"\"\n    if val_position == initial_offset or val_position == 0.0:\n        logging.info('Episode {}/{} - Train Position: {}  Val Position: USELESS  Train Loss: {:.4f}'\n                     .format(result[0], result[1], format_position(result[2]), result[3]))\n    else:\n        logging.info('Episode {}/{} - Train Position: {}  Val Position: {}  Train Loss: {:.4f})'\n                     .format(result[0], result[1], format_position(result[2]), format_position(val_position), result[3],))\n\n\ndef show_eval_result(model_name, profit, initial_offset):\n    \"\"\" Displays eval results\n    \"\"\"\n    if profit == initial_offset or profit == 0.0:\n        logging.info('{}: USELESS\\n'.format(model_name))\n    else:\n        logging.info('{}: {}\\n'.format(model_name, format_position(profit)))\n\n\ndef get_stock_data(stock_file):\n    \"\"\"Reads stock data from csv file\n    \"\"\"\n    df = pd.read_csv(stock_file)\n    return list(df['Adj Close'])\n\n\ndef switch_k_backend_device():\n    \"\"\" Switches `keras` backend from GPU to CPU if required.\n\n    Faster computation on CPU (if using tensorflow-gpu).\n    \"\"\"\n    if K.backend() == \"tensorflow\":\n        logging.debug(\"switching to TensorFlow for CPU\")\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:23:25.255223Z","iopub.execute_input":"2024-01-19T20:23:25.256421Z","iopub.status.idle":"2024-01-19T20:23:25.269015Z","shell.execute_reply.started":"2024-01-19T20:23:25.256385Z","shell.execute_reply":"2024-01-19T20:23:25.267726Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nimport logging\n\nimport numpy as np\n\nfrom tqdm import tqdm\n\n'''from .utils import (\n    format_currency,\n    format_position\n)\nfrom .ops import (\n    get_state\n)\n'''\n\n\ndef train_model(agent, episode, data, ep_count=100, batch_size=32, window_size=10):\n    total_profit = 0\n    data_length = len(data) - 1\n\n    agent.inventory = []\n    avg_loss = []\n\n    state = get_state(data, 0, window_size + 1)\n\n    for t in tqdm(range(data_length), total=data_length, leave=True, desc='Episode {}/{}'.format(episode, ep_count)):        \n        reward = 0\n        next_state = get_state(data, t + 1, window_size + 1)\n\n        # select an action\n        action = agent.act(state)\n\n        # BUY\n        if action == 1:\n            agent.inventory.append(data[t])\n\n        # SELL\n        elif action == 2 and len(agent.inventory) > 0:\n            bought_price = agent.inventory.pop(0)\n            delta = data[t] - bought_price\n            reward = delta #max(delta, 0)\n            total_profit += delta\n\n        # HOLD\n        else:\n            pass\n\n        done = (t == data_length - 1)\n        agent.remember(state, action, reward, next_state, done)\n\n        if len(agent.memory) > batch_size:\n            loss = agent.train_experience_replay(batch_size)\n            avg_loss.append(loss)\n\n        state = next_state\n\n    if episode % 10 == 0:\n        agent.save(episode)\n\n    return (episode, ep_count, total_profit, np.mean(np.array(avg_loss)))\n\n\ndef evaluate_model(agent, data, window_size, debug):\n    total_profit = 0\n    data_length = len(data) - 1\n\n    history = []\n    agent.inventory = []\n    \n    state = get_state(data, 0, window_size + 1)\n\n    for t in range(data_length):        \n        reward = 0\n        next_state = get_state(data, t + 1, window_size + 1)\n        \n        # select an action\n        action = agent.act(state, is_eval=True)\n\n        # BUY\n        if action == 1:\n            agent.inventory.append(data[t])\n\n            history.append((data[t], \"BUY\"))\n            if debug:\n                logging.debug(\"Buy at: {}\".format(format_currency(data[t])))\n        \n        # SELL\n        elif action == 2 and len(agent.inventory) > 0:\n            bought_price = agent.inventory.pop(0)\n            delta = data[t] - bought_price\n            reward = delta #max(delta, 0)\n            total_profit += delta\n\n            history.append((data[t], \"SELL\"))\n            if debug:\n                logging.debug(\"Sell at: {} | Position: {}\".format(\n                    format_currency(data[t]), format_position(data[t] - bought_price)))\n        # HOLD\n        else:\n            history.append((data[t], \"HOLD\"))\n\n        done = (t == data_length - 1)\n        agent.memory.append((state, action, reward, next_state, done))\n\n        state = next_state\n        if done:\n            return total_profit, history","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:23:37.444777Z","iopub.execute_input":"2024-01-19T20:23:37.445771Z","iopub.status.idle":"2024-01-19T20:23:37.469951Z","shell.execute_reply.started":"2024-01-19T20:23:37.445731Z","shell.execute_reply":"2024-01-19T20:23:37.469081Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!pip install coloredlogs","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:23:49.169521Z","iopub.execute_input":"2024-01-19T20:23:49.169927Z","iopub.status.idle":"2024-01-19T20:24:03.599329Z","shell.execute_reply.started":"2024-01-19T20:23:49.169882Z","shell.execute_reply":"2024-01-19T20:24:03.598259Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting coloredlogs\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nScript for evaluating Stock Trading Bot.\n\nUsage:\n  eval.py <eval-stock> [--window-size=<window-size>] [--model-name=<model-name>] [--debug]\n\nOptions:\n  --window-size=<window-size>   Size of the n-day window stock data representation used as the feature vector. [default: 10]\n  --model-name=<model-name>     Name of the pretrained model to use (will eval all models in `models/` if unspecified).\n  --debug                       Specifies whether to use verbose logs during eval operation.\n\"\"\"\n\nimport os\nimport coloredlogs\n\nfrom docopt import docopt\n\n'''from trading_bot.agent import Agent\nfrom trading_bot.methods import evaluate_model\nfrom trading_bot.utils import (\n    get_stock_data,\n    format_currency,\n    format_position,\n    show_eval_result,\n    switch_k_backend_device\n)\n'''\n\ndef main(eval_stock, window_size, model_name, debug):\n    \"\"\" Evaluates the stock trading bot.\n    Please see https://arxiv.org/abs/1312.5602 for more details.\n\n    Args: [python eval.py --help]\n    \"\"\"    \n    data = get_stock_data(eval_stock)\n    initial_offset = data[1] - data[0]\n\n    # Single Model Evaluation\n    if model_name is not None:\n        agent = Agent(window_size, pretrained=True, model_name=model_name)\n        profit, _ = evaluate_model(agent, data, window_size, debug)\n        show_eval_result(model_name, profit, initial_offset)\n        \n    # Multiple Model Evaluation\n    else:\n        for model in os.listdir(\"models\"):\n            if os.path.isfile(os.path.join(\"models\", model)):\n                agent = Agent(window_size, pretrained=True, model_name=model)\n                profit = evaluate_model(agent, data, window_size, debug)\n                show_eval_result(model, profit, initial_offset)\n                del agent\n\n\nif __name__ == \"__main__\":\n    args = docopt(__doc__)\n\n    eval_stock = args[\"<eval-stock>\"]\n    window_size = int(args[\"--window-size\"])\n    model_name = args[\"--model-name\"]\n    debug = args[\"--debug\"]\n\n    coloredlogs.install(level=\"DEBUG\")\n    switch_k_backend_device()\n\n    try:\n        main(eval_stock, window_size, model_name, debug)\n    except KeyboardInterrupt:\n        print(\"Aborted\")","metadata":{"execution":{"iopub.execute_input":"2024-01-18T15:56:42.993471Z","iopub.status.busy":"2024-01-18T15:56:42.991313Z","iopub.status.idle":"2024-01-18T15:56:43.230403Z","shell.execute_reply":"2024-01-18T15:56:43.228904Z","shell.execute_reply.started":"2024-01-18T15:56:42.993350Z"}},"execution_count":8,"outputs":[{"ename":"DocoptLanguageError","evalue":"\"usage:\" (case-insensitive) not found.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDocoptLanguageError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[38;5;28;01mdel\u001b[39;00m agent\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mdocopt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__doc__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     eval_stock \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<eval-stock>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     59\u001b[0m     window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--window-size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/docopt.py:558\u001b[0m, in \u001b[0;36mdocopt\u001b[0;34m(doc, argv, help, version, options_first)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     argv \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 558\u001b[0m DocoptExit\u001b[38;5;241m.\u001b[39musage \u001b[38;5;241m=\u001b[39m \u001b[43mprintable_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m options \u001b[38;5;241m=\u001b[39m parse_defaults(doc)\n\u001b[1;32m    560\u001b[0m pattern \u001b[38;5;241m=\u001b[39m parse_pattern(formal_usage(DocoptExit\u001b[38;5;241m.\u001b[39musage), options)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/docopt.py:468\u001b[0m, in \u001b[0;36mprintable_usage\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    466\u001b[0m usage_split \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([Uu][Ss][Aa][Gg][Ee]:)\u001b[39m\u001b[38;5;124m'\u001b[39m, doc)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(usage_split) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DocoptLanguageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (case-insensitive) not found.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(usage_split) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DocoptLanguageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMore than one \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (case-insensitive).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mDocoptLanguageError\u001b[0m: \"usage:\" (case-insensitive) not found."]}]},{"cell_type":"code","source":"\"\"\"\nScript for training Stock Trading Bot.\n\nUsage:\n  train.py <train-stock> <val-stock> [--strategy=<strategy>]\n    [--window-size=<window-size>] [--batch-size=<batch-size>]\n    [--episode-count=<episode-count>] [--model-name=<model-name>]\n    [--pretrained] [--debug]\n\nOptions:\n  --strategy=<strategy>             Q-learning strategy to use for training the network. Options:\n                                      `dqn` i.e. Vanilla DQN,\n                                      `t-dqn` i.e. DQN with fixed target distribution,\n                                      `double-dqn` i.e. DQN with separate network for value estimation. [default: t-dqn]\n  --window-size=<window-size>       Size of the n-day window stock data representation\n                                    used as the feature vector. [default: 10]\n  --batch-size=<batch-size>         Number of samples to train on in one mini-batch\n                                    during training. [default: 32]\n  --episode-count=<episode-count>   Number of trading episodes to use for training. [default: 50]\n  --model-name=<model-name>         Name of the pretrained model to use. [default: model_debug]\n  --pretrained                      Specifies whether to continue training a previously\n                                    trained model (reads `model-name`).\n  --debug                           Specifies whether to use verbose logs during eval operation.\n\"\"\"\n\nimport logging\nimport coloredlogs\n\nfrom docopt import docopt\n\n'''from trading_bot.agent import Agent\nfrom trading_bot.methods import train_model, evaluate_model\nfrom trading_bot.utils import (\n    get_stock_data,\n    format_currency,\n    format_position,\n    show_train_result,\n    switch_k_backend_device\n)'''\n\ndef main(train_stock, val_stock, window_size, batch_size, ep_count,\n         strategy=\"t-dqn\", model_name=\"model_debug\", pretrained=False,\n         debug=False):\n    \"\"\" Trains the stock trading bot using Deep Q-Learning.\n    Please see https://arxiv.org/abs/1312.5602 for more details.\n\n    Args: [python train.py --help]\n    \"\"\"\n    agent = Agent(window_size, strategy=strategy, pretrained=pretrained, model_name=model_name)\n    \n    train_data = get_stock_data(train_stock)\n    val_data = get_stock_data(val_stock)\n\n    initial_offset = val_data[1] - val_data[0]\n\n    for episode in range(1, ep_count + 1):\n        train_result = train_model(agent, episode, train_data, ep_count=ep_count,\n                                   batch_size=batch_size, window_size=window_size)\n        val_result, _ = evaluate_model(agent, val_data, window_size, debug)\n        show_train_result(train_result, val_result, initial_offset)\n\n\nif __name__ == \"__main__\":\n    args = docopt(__doc__)\n\n    train_stock = args[\"<train-stock>\"]\n    val_stock = args[\"<val-stock>\"]\n    strategy = args[\"--strategy\"]\n    window_size = int(args[\"--window-size\"])\n    batch_size = int(args[\"--batch-size\"])\n    ep_count = int(args[\"--episode-count\"])\n    model_name = args[\"--model-name\"]\n    pretrained = args[\"--pretrained\"]\n    debug = args[\"--debug\"]\n\n    coloredlogs.install(level=\"DEBUG\")\n    switch_k_backend_device()\n\n    try:\n        main(train_stock, val_stock, window_size, batch_size,\n             ep_count, strategy=strategy, model_name=model_name, \n             pretrained=pretrained, debug=debug)\n    except KeyboardInterrupt:\n        print(\"Aborted!\")","metadata":{"execution":{"iopub.execute_input":"2024-01-18T16:01:55.278082Z","iopub.status.busy":"2024-01-18T16:01:55.277583Z","iopub.status.idle":"2024-01-18T16:01:55.380690Z","shell.execute_reply":"2024-01-18T16:01:55.378859Z","shell.execute_reply.started":"2024-01-18T16:01:55.278046Z"}},"execution_count":9,"outputs":[{"ename":"DocoptLanguageError","evalue":"\"usage:\" (case-insensitive) not found.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDocoptLanguageError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m         show_train_result(train_result, val_result, initial_offset)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mdocopt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__doc__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     train_stock \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<train-stock>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     68\u001b[0m     val_stock \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<val-stock>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/docopt.py:558\u001b[0m, in \u001b[0;36mdocopt\u001b[0;34m(doc, argv, help, version, options_first)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     argv \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 558\u001b[0m DocoptExit\u001b[38;5;241m.\u001b[39musage \u001b[38;5;241m=\u001b[39m \u001b[43mprintable_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m options \u001b[38;5;241m=\u001b[39m parse_defaults(doc)\n\u001b[1;32m    560\u001b[0m pattern \u001b[38;5;241m=\u001b[39m parse_pattern(formal_usage(DocoptExit\u001b[38;5;241m.\u001b[39musage), options)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/docopt.py:468\u001b[0m, in \u001b[0;36mprintable_usage\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    466\u001b[0m usage_split \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([Uu][Ss][Aa][Gg][Ee]:)\u001b[39m\u001b[38;5;124m'\u001b[39m, doc)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(usage_split) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DocoptLanguageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (case-insensitive) not found.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(usage_split) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DocoptLanguageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMore than one \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (case-insensitive).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mDocoptLanguageError\u001b[0m: \"usage:\" (case-insensitive) not found."]}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport altair as alt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-01-19T21:32:10.398987Z","iopub.execute_input":"2024-01-19T21:32:10.399413Z","iopub.status.idle":"2024-01-19T21:32:11.956105Z","shell.execute_reply.started":"2024-01-19T21:32:10.399377Z","shell.execute_reply":"2024-01-19T21:32:11.954737Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model_name = 'model_dqn_GOOG_50'\ntest_stock = 'kaggle/input/btc-usd-full-dataset/btc_30m.csv'\nwindow_size = 10\ndebug = True\n\nagent = Agent(window_size, pretrained=True, model_name=model_name)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T21:59:11.263744Z","iopub.execute_input":"2024-01-19T21:59:11.264137Z","iopub.status.idle":"2024-01-19T21:59:11.371404Z","shell.execute_reply.started":"2024-01-19T21:59:11.264106Z","shell.execute_reply":"2024-01-19T21:59:11.369600Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      4\u001b[0m debug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[3], line 54\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[0;34m(self, state_size, strategy, reset_every, pretrained, model_name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m Adam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model()\n","Cell \u001b[0;32mIn[3], line 184\u001b[0m, in \u001b[0;36mAgent.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at models/model_dqn_GOOG_50"],"ename":"OSError","evalue":"No file or directory found at models/model_dqn_GOOG_50","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load the BTC-USD dataset\ndata_path = '/mnt/data/btc_30m.csv'\nbtc_data = pd.read_csv(data_path)\n\n# Preprocess the data\n# Normalize the 'close' prices (as an example of preprocessing)\nscaler = MinMaxScaler()\nbtc_data['close'] = scaler.fit_transform(btc_data['close'].values.reshape(-1,1))\n\n# Display the first few rows of the processed data\nbtc_data.head()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read csv into dataframe\ndf = pd.read_csv(test_stock)\n# filter out the desired features\ndf = df[['Date', 'Adj Close']]\n# rename feature column names\ndf = df.rename(columns={'Adj Close': 'actual', 'Date': 'date'})\n# convert dates from object to DateTime type\ndates = df['date']\ndates = pd.to_datetime(dates, infer_datetime_format=True)\ndf['date'] = dates\n\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\nimport coloredlogs\n\nfrom trading_bot.utils import show_eval_result, switch_k_backend_device, get_stock_data\nfrom trading_bot.methods import evaluate_model\n\ncoloredlogs.install(level='DEBUG')\nswitch_k_backend_device()\n\ntest_data = get_stock_data(test_stock)\ninitial_offset = test_data[1] - test_data[0]\n\ntest_result, history = evaluate_model(agent, test_data, window_size, debug)\nshow_eval_result(model_name, test_result, initial_offset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize(df, history, title=\"trading session\"):\n    # add history to dataframe\n    position = [history[0][0]] + [x[0] for x in history]\n    actions = ['HOLD'] + [x[1] for x in history]\n    df['position'] = position\n    df['action'] = actions\n    \n    # specify y-axis scale for stock prices\n    scale = alt.Scale(domain=(min(min(df['actual']), min(df['position'])) - 50, max(max(df['actual']), max(df['position'])) + 50), clamp=True)\n    \n    # plot a line chart for stock positions\n    actual = alt.Chart(df).mark_line(\n        color='green',\n        opacity=0.5\n    ).encode(\n        x='date:T',\n        y=alt.Y('position', axis=alt.Axis(format='$.2f', title='Price'), scale=scale)\n    ).interactive(\n        bind_y=False\n    )\n    \n    # plot the BUY and SELL actions as points\n    points = alt.Chart(df).transform_filter(\n        alt.datum.action != 'HOLD'\n    ).mark_point(\n        filled=True\n    ).encode(\n        x=alt.X('date:T', axis=alt.Axis(title='Date')),\n        y=alt.Y('position', axis=alt.Axis(format='$.2f', title='Price'), scale=scale),\n        color='action'\n    ).interactive(bind_y=False)\n\n    # merge the two charts\n    chart = alt.layer(actual, points, title=title).properties(height=300, width=1000)\n    \n    return chart","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chart = visualize(df, history, title=test_stock)\nchart","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the trained model (adjust the model loading as necessary)\n# model = load_model('path_to_trained_model')\n\n# Prepare the BTC-USD data for model evaluation\n# Example: Extract features required by the model from btc_data\n# test_data = prepare_data_for_model(btc_data)\n\n# Run the model evaluation\n# Example (pseudo-code):\n# evaluation_results = model.evaluate(test_data)\n\n# Visualization of evaluation results\n# Example: Plotting predicted vs actual prices, or profit/loss over time\nimport matplotlib.pyplot as plt\n\n# Assuming evaluation_results contains predicted prices\n# actual_prices = btc_data['close'][-len(evaluation_results):]\n# predicted_prices = evaluation_results\n\n# Plot actual vs predicted prices\nplt.figure(figsize=(12,6))\nplt.plot(actual_prices, label='Actual Prices')\nplt.plot(predicted_prices, label='Predicted Prices')\nplt.title('BTC-USD: Actual vs Predicted Prices')\nplt.xlabel('Time')\nplt.ylabel('Price')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Method 2: Dueling Deep Q Networks","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load the BTC-USD dataset\ndata_path = '/kaggle/input/btc-usd-full-dataset/btc_30m.csv'\nbtc_data = pd.read_csv(data_path)\n\n# Preprocess the data\n# Normalize the 'close' prices (as an example of preprocessing)\nscaler = MinMaxScaler()\nbtc_data['close'] = scaler.fit_transform(btc_data['close'].values.reshape(-1,1))\n\n# Display the first few rows of the processed data\nbtc_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STATE_SPACE = 28\nACTION_SPACE = 3\n\nACTION_LOW = -1\nACTION_HIGH = 1\n\nGAMMA = 0.9995\nTAU = 1e-3\nEPS_START = 1.0\nEPS_END = 0.1\nEPS_DECAY = 0.9\n\nMEMORY_LEN = 10000\nMEMORY_THRESH = 500\nBATCH_SIZE = 200\n\nLR_DQN = 5e-4\n\nLEARN_AFTER = MEMORY_THRESH\nLEARN_EVERY = 3\nUPDATE_EVERY = 9\n\nCOST = 3e-4\nCAPITAL = 100000\nNEG_MUL = 2","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:26:13.006263Z","iopub.execute_input":"2024-01-19T20:26:13.006730Z","iopub.status.idle":"2024-01-19T20:26:13.014183Z","shell.execute_reply.started":"2024-01-19T20:26:13.006698Z","shell.execute_reply":"2024-01-19T20:26:13.013141Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class DataGetter:\n  \"\"\"\n  The class for getting data for assets.\n  \"\"\"\n\n  def __init__(self, asset=\"BTC-USD\", start_date=None, end_date=None, freq=\"1d\", \n               timeframes=[1, 2, 5, 10, 20, 40]):\n    self.asset = asset\n    self.sd = start_date\n    self.ed = end_date\n    self.freq = freq\n\n    self.timeframes = timeframes\n    self.getData()\n\n    self.scaler = StandardScaler()\n    self.scaler.fit(self.data[:, 1:])\n\n\n  def getData(self):\n    \n    asset = self.asset  \n    if self.sd is not None and self.ed is not None:\n      df =  yf.download([asset], start=self.sd, end=self.ed, interval=self.freq)\n      df_spy = yf.download([\"BTC-USD\"], start=self.sd, end=self.ed, interval=self.freq)\n    elif self.sd is None and self.ed is not None:\n      df =  yf.download([asset], end=self.ed, interval=self.freq)\n      df_spy = yf.download([\"BTC-USD\"], end=self.ed, interval=self.freq)\n    elif self.sd is not None and self.ed is None:\n      df =  yf.download([asset], start=self.sd, interval=self.freq)\n      df_spy = yf.download([\"BTC-USD\"], start=self.sd, interval=self.freq)\n    else:\n      df = yf.download([asset], period=\"max\", interval=self.freq)\n      df_spy = yf.download([\"BTC-USD\"], interval=self.freq)\n    \n    # Reward - Not included in Observation Space.\n    df[\"rf\"] = df[\"Adj Close\"].pct_change().shift(-1)\n\n    # Returns and Trading Volume Changes\n    for i in self.timeframes:\n      df_spy[f\"spy_ret-{i}\"] = df_spy[\"Adj Close\"].pct_change(i)\n      df_spy[f\"spy_v-{i}\"] = df_spy[\"Volume\"].pct_change(i)\n\n      df[f\"r-{i}\"] = df[\"Adj Close\"].pct_change(i)      \n      df[f\"v-{i}\"] = df[\"Volume\"].pct_change(i)\n    \n    # Volatility\n    for i in [5, 10, 20, 40]:\n      df[f'sig-{i}'] = np.log(1 + df[\"r-1\"]).rolling(i).std()\n\n    # Moving Average Convergence Divergence (MACD)\n    df[\"macd_lmw\"] = df[\"r-1\"].ewm(span=26, adjust=False).mean()\n    df[\"macd_smw\"] = df[\"r-1\"].ewm(span=12, adjust=False).mean()\n    df[\"macd_bl\"] = df[\"r-1\"].ewm(span=9, adjust=False).mean()\n    df[\"macd\"] = df[\"macd_smw\"] - df[\"macd_lmw\"]\n\n    # Relative Strength Indicator (RSI)\n    rsi_lb = 5\n    pos_gain = df[\"r-1\"].where(df[\"r-1\"] > 0, 0).ewm(rsi_lb).mean()\n    neg_gain = df[\"r-1\"].where(df[\"r-1\"] < 0, 0).ewm(rsi_lb).mean()\n    rs = np.abs(pos_gain/neg_gain)\n    df[\"rsi\"] = 100 * rs/(1 + rs)\n\n    # Bollinger Bands\n    bollinger_lback = 10\n    df[\"bollinger\"] = df[\"r-1\"].ewm(bollinger_lback).mean()\n    df[\"low_bollinger\"] = df[\"bollinger\"] - 2 * df[\"r-1\"].rolling(bollinger_lback).std()\n    df[\"high_bollinger\"] = df[\"bollinger\"] + 2 * df[\"r-1\"].rolling(bollinger_lback).std()\n\n    # SP500\n    df = df.merge(df_spy[[f\"spy_ret-{i}\" for i in self.timeframes] + [f\"spy_sig-{i}\" for i in [5, 10, 20, 40]]], \n                  how=\"left\", right_index=True, left_index=True)\n\n    # Filtering\n    for c in df.columns:\n      df[c].interpolate('linear', limit_direction='both', inplace=True)\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df.dropna(inplace=True)\n\n    self.frame = df\n    self.data = np.array(df.iloc[:, 6:])\n    return\n\n\n  def scaleData(self):\n    self.scaled_data = self.scaler.fit_transform(self.data[:, 1:])\n    return\n\n\n  def __len__(self):\n    return len(self.data)\n\nclass DataGetter:\n  \"\"\"\n  The class for getting data for assets.\n  \"\"\"\n\n  def __init__(self, asset=\"BTC-USD\", start_date=None, end_date=None, freq=\"1d\", \n               timeframes=[1, 2, 5, 10, 20, 40]):\n    self.asset = asset\n    self.sd = start_date\n    self.ed = end_date\n    self.freq = freq\n\n    self.timeframes = timeframes\n    self.getData()\n\n    self.scaler = StandardScaler()\n    self.scaler.fit(self.data[:, 1:])\n\n\n  def getData(self):\n    \n    asset = self.asset  \n    if self.sd is not None and self.ed is not None:\n      df =  yf.download([asset], start=self.sd, end=self.ed, interval=self.freq)\n      df_spy = yf.download([\"BTC-USD\"], start=self.sd, end=self.ed, interval=self.freq)\n    elif self.sd is None and self.ed is not None:\n      df =  yf.download([asset], end=self.ed, interval=self.freq)\n      df_spy = yf.download([\"BTC-USD\"], end=self.ed, interval=self.freq)\n    elif self.sd is not None and self.ed is None:\n      df =  yf.download([asset], start=self.sd, interval=self.freq)\n      df_spy = yf.download([\"BTC-USD\"], start=self.sd, interval=self.freq)\n    else:\n      df = yf.download([asset], period=\"max\", interval=self.freq)\n      df_spy = yf.download([\"BTC-USD\"], interval=self.freq)\n    \n    # Reward - Not included in Observation Space.\n    df[\"rf\"] = df[\"Adj Close\"].pct_change().shift(-1)\n\n    # Returns and Trading Volume Changes\n    for i in self.timeframes:\n      df_spy[f\"spy_ret-{i}\"] = df_spy[\"Adj Close\"].pct_change(i)\n      df_spy[f\"spy_v-{i}\"] = df_spy[\"Volume\"].pct_change(i)\n\n      df[f\"r-{i}\"] = df[\"Adj Close\"].pct_change(i)      \n      df[f\"v-{i}\"] = df[\"Volume\"].pct_change(i)\n    \n    # Volatility\n    for i in [5, 10, 20, 40]:\n      df[f'sig-{i}'] = np.log(1 + df[\"r-1\"]).rolling(i).std()\n\n    # Moving Average Convergence Divergence (MACD)\n    df[\"macd_lmw\"] = df[\"r-1\"].ewm(span=26, adjust=False).mean()\n    df[\"macd_smw\"] = df[\"r-1\"].ewm(span=12, adjust=False).mean()\n    df[\"macd_bl\"] = df[\"r-1\"].ewm(span=9, adjust=False).mean()\n    df[\"macd\"] = df[\"macd_smw\"] - df[\"macd_lmw\"]\n\n    # Relative Strength Indicator (RSI)\n    rsi_lb = 5\n    pos_gain = df[\"r-1\"].where(df[\"r-1\"] > 0, 0).ewm(rsi_lb).mean()\n    neg_gain = df[\"r-1\"].where(df[\"r-1\"] < 0, 0).ewm(rsi_lb).mean()\n    rs = np.abs(pos_gain/neg_gain)\n    df[\"rsi\"] = 100 * rs/(1 + rs)\n\n    # Bollinger Bands\n    bollinger_lback = 10\n    df[\"bollinger\"] = df[\"r-1\"].ewm(bollinger_lback).mean()\n    df[\"low_bollinger\"] = df[\"bollinger\"] - 2 * df[\"r-1\"].rolling(bollinger_lback).std()\n    df[\"high_bollinger\"] = df[\"bollinger\"] + 2 * df[\"r-1\"].rolling(bollinger_lback).std()\n\n    # SP500\n    df = df.merge(df_spy[[f\"spy_ret-{i}\" for i in self.timeframes] + [f\"spy_sig-{i}\" for i in [5, 10, 20, 40]]], \n                  how=\"left\", right_index=True, left_index=True)\n\n    # Filtering\n    for c in df.columns:\n      df[c].interpolate('linear', limit_direction='both', inplace=True)\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df.dropna(inplace=True)\n\n    self.frame = df\n    self.data = np.array(df.iloc[:, 6:])\n    return\n\n\n  def scaleData(self):\n    self.scaled_data = self.scaler.fit_transform(self.data[:, 1:])\n    return\n\n\n  def __len__(self):\n    return len(self.data)\n\n\n  def __getitem__(self, idx, col_idx=None):\n    if col_idx is None:\n      return self.data[idx]\n    elif col_idx < len(list(self.data.columns)):\n      return self.data[idx][col_idx]\n    else:\n      raise IndexError\n  def __getitem__(self, idx, col_idx=None):\n    if col_idx is None:\n      return self.data[idx]\n    elif col_idx < len(list(self.data.columns)):\n      return self.data[idx][col_idx]\n    else:\n      raise IndexError","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:26:17.528314Z","iopub.execute_input":"2024-01-19T20:26:17.528713Z","iopub.status.idle":"2024-01-19T20:26:17.556836Z","shell.execute_reply.started":"2024-01-19T20:26:17.528683Z","shell.execute_reply":"2024-01-19T20:26:17.555715Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class BTCUSDTradingEnv:\n    def __init__(self, data, window_size=10):\n        self.data = data\n        self.window_size = window_size\n        self.current_step = window_size\n        self.done = False\n\n    def reset(self):\n        self.current_step = self.window_size\n        self.done = False\n        return self._get_state()\n\n    def _get_state(self):\n        # Using 'close' prices as the state for simplicity\n        return self.data['close'][self.current_step - self.window_size:self.current_step].values\n\n    def step(self, action):\n        # Assuming action is 0 (sell), 1 (hold), 2 (buy)\n        # Simple reward: price change between steps\n        reward = 0\n        self.current_step += 1\n        if self.current_step >= len(self.data):\n            self.done = True\n            return self._get_state(), reward, self.done, {}\n        \n        if action == 2:  # Buy\n            reward = self.data['close'][self.current_step] - self.data['close'][self.current_step - 1]\n        elif action == 0:  # Sell\n            reward = self.data['close'][self.current_step - 1] - self.data['close'][self.current_step]\n        \n        return self._get_state(), reward, self.done, {}\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import deque\n\nclass ReplayBuffer:\n    def __init__(self, capacity):\n        self.buffer = deque(maxlen=capacity)\n\n    def add(self, state, action, reward, next_state, done):\n        self.buffer.append((state, action, reward, next_state, done))\n\n    def sample(self, batch_size):\n        return random.sample(self.buffer, batch_size)\n\nreplay_memory = ReplayBuffer(capacity=MEMORY_LEN)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPISODES = 100  # Set this to the desired number of training episodes\n\nenv = BTCUSDTradingEnv(data=btc_data, window_size=STATE_SPACE)\ntotal_rewards = []\n\nfor episode in range(N_EPISODES):\n    state = env.reset()\n    total_reward = 0\n    done = False\n    while not done:\n        action = np.random.choice(ACTION_SPACE)  # Random action, replace with model's prediction\n        next_state, reward, done, _ = env.step(action)\n        replay_memory.add(state, action, reward, next_state, done)\n        state = next_state\n        total_reward += reward\n    total_rewards.append(total_reward)\n    print(f\"Episode: {episode}, Total Reward: {total_reward}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plotting the total rewards per episode\nplt.plot(total_rewards)\nplt.title(\"Total Rewards Per Episode\")\nplt.xlabel(\"Episode\")\nplt.ylabel(\"Total Reward\")\nplt.show()\n\n# Additional visualizations can be added here, such as predicted vs actual prices, if applicable\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SingleAssetTradingEnvironment:\n  \"\"\"\n  Trading Environment for trading a single asset.\n  The Agent interacts with the environment class through the step() function.\n  Action Space: {-1: Sell, 0: Do Nothing, 1: Buy}\n  \"\"\"\n\n  def __init__(self, asset_data,\n               initial_money=CAPITAL, trans_cost=COST, store_flag=1, asset_ph=0, \n               capital_frac=0.2, running_thresh=0.1, cap_thresh=0.3):\n\n    self.past_holding = asset_ph\n    self.capital_frac = capital_frac # Fraction of capital to invest each time.\n    self.cap_thresh = cap_thresh\n    self.running_thresh = running_thresh\n    self.trans_cost = trans_cost\n\n    self.asset_data = asset_data\n    self.terminal_idx = len(self.asset_data) - 1\n    self.scaler = self.asset_data.scaler    \n\n    self.initial_cap = initial_money\n\n    self.capital = self.initial_cap\n    self.running_capital = self.capital\n    self.asset_inv = self.past_holding\n\n    self.pointer = 0\n    self.next_return, self.current_state = 0, None\n    self.prev_act = 0\n    self.current_act = 0\n    self.current_reward = 0\n    self.current_price = self.asset_data.frame.iloc[self.pointer, :]['Adj Close']\n    self.done = False\n\n    self.store_flag = store_flag\n    if self.store_flag == 1:\n      self.store = {\"action_store\": [],\n                    \"reward_store\": [],\n                    \"running_capital\": [],\n                    \"port_ret\": []}\n\n\n  def reset(self):\n    self.capital = self.initial_cap\n    self.running_capital = self.capital\n    self.asset_inv = self.past_holding\n\n    self.pointer = 0\n    self.next_return, self.current_state = self.get_state(self.pointer)\n    self.prev_act = 0\n    self.current_act = 0\n    self.current_reward = 0\n    self.current_price = self.asset_data.frame.iloc[self.pointer, :]['Adj Close']\n    self.done = False\n    \n    if self.store_flag == 1:\n      self.store = {\"action_store\": [],\n                    \"reward_store\": [],\n                    \"running_capital\": [],\n                    \"port_ret\": []}\n\n    return self.current_state\n\n\n  def step(self, action):\n    self.current_act = action\n    self.current_price = self.asset_data.frame.iloc[self.pointer, :]['Adj Close']\n    self.current_reward = self.calculate_reward()\n    self.prev_act = self.current_act\n    self.pointer += 1\n    self.next_return, self.current_state = self.get_state(self.pointer)\n    self.done = self.check_terminal()\n\n    if self.done:\n      reward_offset = 0\n      ret = (self.store['running_capital'][-1]/self.store['running_capital'][-0]) - 1\n      if self.pointer < self.terminal_idx:\n        reward_offset += -1 * max(0.5, 1 - self.pointer/self.terminal_idx)\n      if self.store_flag:\n        reward_offset += 10 * ret\n      self.current_reward += reward_offset\n\n    if self.store_flag:\n      self.store[\"action_store\"].append(self.current_act)\n      self.store[\"reward_store\"].append(self.current_reward)\n      self.store[\"running_capital\"].append(self.capital)\n      info = self.store\n    else:\n      info = None\n    \n    return self.current_state, self.current_reward, self.done, info\n\n\n  def calculate_reward(self):\n    investment = self.running_capital * self.capital_frac\n    reward_offset = 0\n\n    # Buy Action\n    if self.current_act == 1: \n      if self.running_capital > self.initial_cap * self.running_thresh:\n        self.running_capital -= investment\n        asset_units = investment/self.current_price\n        self.asset_inv += asset_units\n        self.current_price *= (1 - self.trans_cost)\n\n    # Sell Action\n    elif self.current_act == -1:\n      if self.asset_inv > 0:\n        self.running_capital += self.asset_inv * self.current_price * (1 - self.trans_cost)\n        self.asset_inv = 0\n\n    # Do Nothing\n    elif self.current_act == 0:\n      if self.prev_act == 0:\n        reward_offset += -0.1\n      pass\n    \n    # Reward to give\n    prev_cap = self.capital\n    self.capital = self.running_capital + (self.asset_inv) * self.current_price\n    reward = 100*(self.next_return) * self.current_act - np.abs(self.current_act - self.prev_act) * self.trans_cost\n    if self.store_flag==1:\n      self.store['port_ret'].append((self.capital - prev_cap)/prev_cap)\n    \n    if reward < 0:\n      reward *= NEG_MUL  # To make the Agent more risk averse towards negative returns.\n    reward += reward_offset\n\n    return reward\n\n\n  def check_terminal(self):\n    if self.pointer == self.terminal_idx:\n      return True\n    elif self.capital <= self.initial_cap * self.cap_thresh:\n      return True\n    else:\n      return False\n\n\n  def get_state(self, idx):\n    state = self.asset_data[idx][1:]\n    state = self.scaler.transform(state.reshape(1, -1))\n\n    state = np.concatenate([state, [[self.capital/self.initial_cap,\n                                     self.running_capital/self.capital,\n                                     self.asset_inv * self.current_price/self.initial_cap,\n                                     self.prev_act]]], axis=-1)\n    \n    next_ret = self.asset_data[idx][0]\n    return next_ret, state","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:26:22.137208Z","iopub.execute_input":"2024-01-19T20:26:22.137707Z","iopub.status.idle":"2024-01-19T20:26:22.173511Z","shell.execute_reply.started":"2024-01-19T20:26:22.137664Z","shell.execute_reply":"2024-01-19T20:26:22.172304Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from collections import namedtuple\nTransition = namedtuple(\"Transition\", [\"States\", \"Actions\", \"Rewards\", \"NextStates\", \"Dones\"])\n\n\nclass ReplayMemory:\n  \"\"\"\n  Implementation of Agent memory\n  \"\"\"\n  def __init__(self, capacity=MEMORY_LEN):\n    self.memory = deque(maxlen=capacity)\n\n  def store(self, t):\n    self.memory.append(t)\n\n  def sample(self, n):\n    a = random.sample(self.memory, n)\n    return a\n\n  def __len__(self):\n    return len(self.memory)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T20:26:28.687200Z","iopub.execute_input":"2024-01-19T20:26:28.687587Z","iopub.status.idle":"2024-01-19T20:26:29.584539Z","shell.execute_reply.started":"2024-01-19T20:26:28.687560Z","shell.execute_reply":"2024-01-19T20:26:29.582977Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Transition \u001b[38;5;241m=\u001b[39m \u001b[43mnamedtuple\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransition\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRewards\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNextStates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDones\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mReplayMemory\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m  Implementation of Agent memory\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'namedtuple' is not defined"],"ename":"NameError","evalue":"name 'namedtuple' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import torch.nn as nn\nclass DuellingDQN(nn.Module):\n  \"\"\"\n  Acrchitecture for Duelling Deep Q Network Agent\n  \"\"\"\n\n  def __init__(self, input_dim=STATE_SPACE, output_dim=ACTION_SPACE):\n    super(DuellingDQN, self).__init__()\n    self.input_dim = input_dim\n    self.output_dim = output_dim\n\n    self.fc1 = nn.Linear(self.input_dim, 500)\n    self.fc2 = nn.Linear(500, 500)\n    self.fc3 = nn.Linear(500, 300)\n    self.fc4 = nn.Linear(300, 200)\n    self.fc5 = nn.Linear(200, 10)\n\n    self.fcs = nn.Linear(10, 1)\n    self.fcp = nn.Linear(10, self.output_dim)\n    self.fco = nn.Linear(self.output_dim + 1, self.output_dim)\n\n    self.relu = nn.ReLU()\n    self.tanh = nn.Tanh()\n    self.sig = nn.Sigmoid()\n    self.sm = nn.Softmax(dim=1)\n\n  def forward(self, state):\n    x = self.relu(self.fc1(state))\n    x = self.relu(self.fc2(x))\n    x = self.relu(self.fc3(x))\n    x = self.relu(self.fc4(x))\n    x = self.relu(self.fc5(x))\n    xs = self.relu(self.fcs(x))\n    xp = self.relu(self.fcp(x))\n\n    x = xs + xp - xp.mean()\n    return x\n\n\nclass DQNAgent:\n  \"\"\"\n  Implements the Agent components\n  \"\"\"\n\n  def __init__(self, actor_net=DuellingDQN, memory=ReplayMemory()):\n    \n    self.actor_online = actor_net(STATE_SPACE, ACTION_SPACE).to(DEVICE)\n    self.actor_target = actor_net(STATE_SPACE, ACTION_SPACE).to(DEVICE)\n    self.actor_target.load_state_dict(self.actor_online.state_dict())\n    self.actor_target.eval()\n\n    self.memory = memory\n\n    self.actor_criterion = nn.MSELoss()\n    self.actor_op = optim.Adam(self.actor_online.parameters(), lr=LR_DQN)\n\n    self.t_step = 0\n\n\n  def act(self, state, eps=0.):\n    self.t_step += 1\n    state = torch.from_numpy(state).float().to(DEVICE).view(1, -1)\n    \n    self.actor_online.eval()\n    with torch.no_grad():\n      actions = self.actor_online(state)\n    self.actor_online.train()\n\n    if random.random() > eps:\n      act = np.argmax(actions.cpu().data.numpy())\n    else:\n      act = random.choice(np.arange(ACTION_SPACE))\n    return int(act)\n\n\n  def learn(self):\n    if len(self.memory) <= MEMORY_THRESH:\n      return 0\n\n    if self.t_step > LEARN_AFTER and self.t_step % LEARN_EVERY==0:\n    # Sample experiences from the Memory\n      batch = self.memory.sample(BATCH_SIZE)\n\n      states = np.vstack([t.States for t in batch])\n      states = torch.from_numpy(states).float().to(DEVICE)\n\n      actions = np.vstack([t.Actions for t in batch])\n      actions = torch.from_numpy(actions).float().to(DEVICE)\n\n      rewards = np.vstack([t.Rewards for t in batch])\n      rewards = torch.from_numpy(rewards).float().to(DEVICE)\n\n      next_states = np.vstack([t.NextStates for t in batch])\n      next_states = torch.from_numpy(next_states).float().to(DEVICE)\n\n      dones = np.vstack([t.Dones for t in batch]).astype(np.uint8)\n      dones = torch.from_numpy(dones).float().to(DEVICE)\n\n      # ACTOR UPDATE\n      # Compute next state actions and state values\n      next_state_values = self.actor_target(next_states).max(1)[0].unsqueeze(1)\n      y = rewards + (1-dones) * GAMMA * next_state_values\n      state_values = self.actor_online(states).gather(1, actions.type(torch.int64))\n      # Compute Actor loss\n      actor_loss = self.actor_criterion(y, state_values)\n      # Minimize Actor loss\n      self.actor_op.zero_grad()\n      actor_loss.backward()\n      self.actor_op.step()\n\n      if self.t_step % UPDATE_EVERY == 0:\n        self.soft_update(self.actor_online, self.actor_target)\n      # return actor_loss.item()\n\n\n  def soft_update(self, local_model, target_model, tau=TAU):\n    for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n      target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Environment and Agent Initiation\n\n## Cryptocurrency Tickers\nasset_codes = [\"ETH-USD\", \"BNB-USD\", \"XRP-USD\", \"SOL-USD\", \"DOGE-USD\", \n               \"ADA-USD\", \"MATIC-USD\", \"AVAX-USD\", \"WAVES-USD\"]\n\n## Training and Testing Environments\nassets = [DataGetter(a, start_date=\"2015-01-01\", end_date=\"2021-05-01\") for a in asset_codes]\ntest_assets = [DataGetter(a, start_date=\"2021-05-01\", end_date=\"2022-05-01\", freq=\"1d\") for a in asset_codes]\nenvs = [SingleAssetTradingEnvironment(a) for a in assets]\ntest_envs = [SingleAssetTradingEnvironment(a) for a in test_assets]\n\n## Agent\nmemory = ReplayMemory()\nagent = DQNAgent(actor_net=DuellingDQN, memory=memory)\n\n# Main training loop\nN_EPISODES = 20 # No of episodes/epochs\nscores = []\neps = EPS_START\nact_dict = {0:-1, 1:1, 2:0}\n\nte_score_min = -np.Inf\nfor episode in range(1, 1 + N_EPISODES):\n  counter = 0\n  episode_score = 0\n  episode_score2 = 0\n  test_score = 0\n  test_score2 = 0\n\n  for env in envs:\n    score = 0\n    state = env.reset()\n    state = state.reshape(-1, STATE_SPACE)\n    while True:\n      actions = agent.act(state, eps)\n      action = act_dict[actions]\n      next_state, reward, done, _ = env.step(action)\n      next_state = next_state.reshape(-1, STATE_SPACE)\n\n      t = Transition(state, actions, reward, next_state, done)\n      agent.memory.store(t)\n      agent.learn()\n\n      state = next_state\n      score += reward\n      counter += 1\n      if done:\n        break\n\n    episode_score += score\n    episode_score2 += (env.store['running_capital'][-1] - env.store['running_capital'][0])\n\n  scores.append(episode_score)\n  eps = max(EPS_END, EPS_DECAY * eps)\n\n  for i, test_env in enumerate(test_envs):\n    state = test_env.reset()\n    done = False\n    score_te = 0\n    scores_te = [score_te]\n\n    while True:\n      actions = agent.act(state)\n      action = act_dict[actions]\n      next_state, reward, done, _ = test_env.step(action)\n      next_state = next_state.reshape(-1, STATE_SPACE)\n      state= next_state\n      score_te += reward\n      scores_te.append(score_te)\n      if done:\n        break\n\n    test_score += score_te\n    test_score2 += (test_env.store['running_capital'][-1] - test_env.store['running_capital'][0])\n  if test_score > te_score_min:\n    te_score_min = test_score\n    torch.save(agent.actor_online.state_dict(), \"online.pt\")\n    torch.save(agent.actor_target.state_dict(), \"target.pt\")\n\n  print(f\"Episode: {episode}, Train Score: {episode_score:.5f}, Validation Score: {test_score:.5f}\")\n  print(f\"Episode: {episode}, Train Value: ${episode_score2:.5f}, Validation Value: ${test_score2:.5f}\", \"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Environment and Agent Initiation\nfrom sklearn.preprocessing import StandardScaler\n## Cryptocurrency Tickers\nasset_codes = [\"ETH-USD\", \"BNB-USD\", \"XRP-USD\", \"SOL-USD\", \"DOGE-USD\", \n               \"ADA-USD\", \"MATIC-USD\", \"AVAX-USD\", \"WAVES-USD\"]\n\n## Training and Testing Environments\nassets = [DataGetter(a, start_date=\"2018-01-01\", end_date=\"2021-05-01\") for a in asset_codes]\ntest_assets = [DataGetter(a, start_date=\"2021-05-01\", end_date=\"2022-05-01\", freq=\"30m\") for a in asset_codes]\nenvs = [SingleAssetTradingEnvironment(a) for a in assets]\ntest_envs = [SingleAssetTradingEnvironment(a) for a in test_assets]\n\n## Agent\nmemory = ReplayMemory()\nagent = DQNAgent(actor_net=DuellingDQN, memory=memory)\n\n# Main training loop\nN_EPISODES = 20 # No of episodes/epochs\nscores = []\neps = EPS_START\nact_dict = {0:-1, 1:1, 2:0}\n\nte_score_min = -np.Inf\nfor episode in range(1, 1 + N_EPISODES):\n  counter = 0\n  episode_score = 0\n  episode_score2 = 0\n  test_score = 0\n  test_score2 = 0\n\n  for env in envs:\n    score = 0\n    state = env.reset()\n    state = state.reshape(-1, STATE_SPACE)\n    while True:\n      actions = agent.act(state, eps)\n      action = act_dict[actions]\n      next_state, reward, done, _ = env.step(action)\n      next_state = next_state.reshape(-1, STATE_SPACE)\n\n      t = Transition(state, actions, reward, next_state, done)\n      agent.memory.store(t)\n      agent.learn()\n\n      state = next_state\n      score += reward\n      counter += 1\n      if done:\n        break\n\n    episode_score += score\n    episode_score2 += (env.store['running_capital'][-1] - env.store['running_capital'][0])\n\n  scores.append(episode_score)\n  eps = max(EPS_END, EPS_DECAY * eps)\n\n  for i, test_env in enumerate(test_envs):\n    state = test_env.reset()\n    done = False\n    score_te = 0\n    scores_te = [score_te]\n\n    while True:\n      actions = agent.act(state)\n      action = act_dict[actions]\n      next_state, reward, done, _ = test_env.step(action)\n      next_state = next_state.reshape(-1, STATE_SPACE)\n      state= next_state\n      score_te += reward\n      scores_te.append(score_te)\n      if done:\n        break\n\n    test_score += score_te\n    test_score2 += (test_env.store['running_capital'][-1] - test_env.store['running_capital'][0])\n  if test_score > te_score_min:\n    te_score_min = test_score\n    torch.save(agent.actor_online.state_dict(), \"online.pt\")\n    torch.save(agent.actor_target.state_dict(), \"target.pt\")\n\n  print(f\"Episode: {episode}, Train Score: {episode_score:.5f}, Validation Score: {test_score:.5f}\")\n  print(f\"Episode: {episode}, Train Value: ${episode_score2:.5f}, Validation Value: ${test_score2:.5f}\", \"\\n\")","metadata":{},"execution_count":null,"outputs":[]}]}